<!DOCTYPE html>
<html lang="en">
<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-84629802-4"></script>
	<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'UA-84629802-4');
	</script>

	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<meta name="description" content="">
	<meta name="author" content="">
	<meta name="keywords" content="EPOS, 6D object pose, pose estimation, symmetry" />

	<title>CVPR Tutorial 2021</title>

	<link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/style.css?1613208907a" rel="stylesheet">
</head>

<body>
<div class="container">

<!--<div class="topnav">
	<div>Opening words</div>
	<div>Introduction</div>
	<div>Traditional approaches</div>
	<div>Latest developments of RANSAC</div>
	<div>Mathematical programming</div>
	<div>Differentiable approaches</div>
	<div>Experiments</div>
</div>-->
	
<div class="container">
	<p class="title">Mobile Visual Analytics</p>
</div>

<!--<div class="block">

	<p class="subtitle">Important</p>

	<p class="text">
	The processed videos will be uploaded soon.</p>
</div>-->

<div class="container">

	<p class="subtitle">Overview of the Tutorial</p>

	<p class="text">As mobile devices and real-time scenarios are becoming more ubiquitous and prevalent, research on mobile visual analytics is extremely urgent. The purpose of mobile visual analytics is to enable entirely new on-device experiences. In the past few years, some effective techniques in mobile visual analytics have been developed to address many challenging issues in many aspects such as real-time detection or segmentation tasks under dynamically changing scenes and computationally constrained resources.</p>

	<p class="text">In this tutorial, we first introduce some preliminaries of the tutorial and state-of-the-art approaches in some mobile visual tasks. Then, we present in-depth studies and analyses on the recently developed mobile visual techniques, including efficient backbone network design for mobile usage, generative adversarial network for mobile applications, and finally the context-aware algorithms under dynamic background for moving cameras. This topic covers two main aspects of mobile visual analytics: methods that can accelerate AI algorithms run for computational resource-constrained devices, and techniques that can leverage the contextual information under dynamic environments for mobile devices.</p>
</div>

<div class="container">
	<p class="subtitle">Organizers</p>
	
		
	<div class="organizers-box">
	 
		<div class="organizer-box">
			<img class="organizer-picture" src="assets/ct.jpg">
			<p class="name">Dr. Chen Tao</p>
			<p class="email"><font size="4">eetchen@fudan.edu.cn</font></p>
			<a target="blank" href="http://homepage.fudan.edu.cn/eetchen/"><font size="4" color="blue">HomePage</font></a>
		</div>
	 
		<div class="organizer-box">
			<img class="organizer-picture" src="assets/gh.jpg">
			<p class="name">Dr. Gao Huang</p>
			<p class="email"><font size="4">gaohuang@tsinghua.com</font></p>
			<a target="blank" href="http://www.gaohuang.net/"><font size="4" color="blue">HomePage</font></a>
		</div>
	 
		<div class="organizer-box">
			<img class="organizer-picture" src="assets/yg.jpg">
			<p class="name">Dr. Gang Yu</p>
			<p class="email"><font size="4">skicy@outlook.com</font></p>
			<a target="blank" href="https://www.skicyyu.org/"><font size="4" color="blue">HomePage</font></a>
		</div>
	 
		</div>
</div>


<div class="container">

	<p class="subtitle">Schedule of the Tutorial</p>
	<p class="text"> 10:00-10:10 AM (Est Time), June 20, 2021  Opening Remarks (Tao Chen)</p>
	<p class="text"> 10:10-11:10 AM (Est Time), June 20, 2021   Convolutional Networks for Mobile Applications (Gao Huang)</p>
	<p class="text"> 11:10-12:10 PM (Est Time), June 20, 2021     Generative Adversarial Network for Mobile Applications (Gang Yu)</p>
	<p class="text"> 12:10-1:10  PM (Est Time), June 20, 2021     Context-aware Mobile Visual Analysis (Tao Chen)</p>
	<p class="text"> 1:10-1:30 PM (Est Time), June 20, 2021   Questions and Panel Discussion</p>


<div class="container" style="border-width: 0 0 0 0;">
	
	<div class="talk-separator">
		Convolutional Networks for Mobile Applications
	</div>
	
	<table class="schedule-table">
		<tr>
			<td><font class="title">Official time</font><br>10:10-11:10 AM (Est Time), June 20, 2021</td>
			<td><font class="title">Presenter</font><br>Dr. Gao Huang</td>
			<td><img class="organizer-picture" src="assets/gh.jpg"></td>
			<td rowspan=5><iframe width="560" height="315" src="" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
		</tr>
		<tr>
			<td colspan=3><font class="title">Short description</font></td>
		</tr>
		<tr>
			<td colspan=3><div>Convolutional neural networks (CNNs) have been widely used as the backbone model in computer vision, and network architecture innovations are pushing forward the application of deep learning on mobile devices. This part of the tutorial will first review the SOTA efficient CNN backbones such as MobileNet, ShuffleNet, CondenseNet, etc, which adopt static structures and parameters. Then, we will focus on dynamic convolutional networks which improve the inference efficiency with data-dependent architectures or parameters. In specific, we will introduce three types of dynamic networks, namely, sample-wise, spatial-wise and temporal-wise dynamic models. The advantages and limitations of them as well as future directions will be discussed.</div></td>
		</tr>
		<tr>
			<td colspan=3><font class="title">Presentation</font></td>
		</tr>
		<tr>
			<td colspan=3><div><a target="blank" href="presentations/cvpr-2021-gh.pdf">Link to PDF</a></div></td>
		<tr>
			<td colspan=3><div><a target="blank" href="presentations/cvpr-2021-ct.pdf">Link to Video</a></div></td>
		</tr>
	</table>
	
	<div class="talk-separator">
		Generative Adversarial Network for Mobile Applications
	</div>
	
	<table class="schedule-table">
		<tr>
			<td><font class="title">Official time</font><br>11:10-12:10 PM (Est Time), June 20, 2021</td>
			<td><font class="title">Presenter</font><br>Dr. Gang Yu</td>
			<td><img class="organizer-picture" src="assets/yg.jpg"></td>
			<td rowspan=5><iframe width="560" height="315" src="" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
		</tr>
		<tr>
			<td colspan=3><font class="title">Short description</font></td>
		</tr>
		<tr>
			<td colspan=3><div>Generative Adversarial Network (GAN) has been introduced in 2014 and has been rapidly developed in the recent five years. In industry, GAN has been applied for mobile devices with impressive applications like Face Cartoon generation and human pose transfer. In this tutorial, we will give the techniques underlying these GAN based applications. More specifically, we will first start from introduction of the GAN technique. Then we will describe the GAN application from different aspects like Face, Human, and Font. Finally, the techniques which are important for mobile applications will also be highlighted in the tutorial. 
</div></td>
		</tr>
		<tr>
			<td colspan=3><font class="title">Presentation</font></td>
		</tr>
		<tr>
			<td colspan=3><div><a target="blank" href="presentations/cvpr-2021-yg.pdf">Link to PDF</a></div></td>
		<tr>
			<td colspan=3><div><a target="blank" href="presentations/cvpr-2021-ct.pdf">Link to Video</a></div></td>
		</tr>
	</table>
	
	<div class="talk-separator">
		Context-aware Mobile Visual Analysis
	</div>
	
	<table class="schedule-table">
		<tr>
			<td><font class="title">Official time</font><br>12:10-1:10 PM   (Est Time), June 20, 2021</td>
			<td><font class="title">Presenter</font><br>Dr. Tao Chen</td>
			<td><img class="organizer-picture" src="assets/ct.jpg"></td>
			<td rowspan=5><iframe width="560" height="315" src="" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
		</tr>
		<tr>
			<td colspan=3><font class="title">Short description</font></td>
		</tr>
		<tr>
			<td colspan=3><div>The above-mentioned design scheme for the lightweight model mainly focuses on network structure and optimization objective design (different objectives dependent on different tasks) , they still do not consider the dynamically changing background and foreground under moving cameras, and also do not fully utilize the context information including temporal and spatially for inference. In this part, we will discuss some effective context-aware analysis techniques for moving cameras, and give in-depth study on how to utilize the temporal contextual information such as object motion, and spatial information such as surrounding objects centering around an object-of-interest for fast and accurate mobile vision analytics. In particular, some typical scenarios such as object-level motion detection, context-aware pedestrian intrusion detection will be introduced. </div></td>
		</tr>
		<tr>
			<td colspan=3><font class="title">Presentation</font></td>
		</tr>
		<tr>
			<td colspan=3><div><a target="blank" href="presentations/cvpr-2021-ct.pdf">Link to PDF</a></div></td>
		<tr>
			<td colspan=3><div><a target="blank" href="presentations/cvpr-2021-ct.pdf">Link to Video</a></div></td>
		</tr>
	</table>
	
	
</div>

</div>

<!-- Bootstrap core JavaScript -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="js/vendor/jquery.min.js"><\/script>')</script>
<script src="js/bootstrap.min.js"></script>

</body>
</html>
